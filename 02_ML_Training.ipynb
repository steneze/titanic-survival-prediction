{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35490094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset charg√© : (891, 21)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# TITANIC - MACHINE LEARNING\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================\n",
    "# 1. CHARGEMENT DES DONN√âES ENGINEER√âES\n",
    "# ============================================================\n",
    "\n",
    "data = pd.read_csv('data/train_engineered_final.csv')\n",
    "print(f\"‚úÖ Dataset charg√© : {data.shape}\")\n",
    "\n",
    "# ============================================================\n",
    "# 2. S√âLECTION & PR√âPARATION DES FEATURES\n",
    "# ============================================================\n",
    "\n",
    "# √Ä d√©finir ensemble...\n",
    "\n",
    "# ============================================================\n",
    "# 3. ENCODAGE DES VARIABLES CAT√âGORIELLES\n",
    "# ============================================================\n",
    "\n",
    "# √Ä faire...\n",
    "\n",
    "# ============================================================\n",
    "# 4. TRAIN/TEST SPLIT\n",
    "# ============================================================\n",
    "\n",
    "# √Ä faire...\n",
    "\n",
    "# ============================================================\n",
    "# 5. ENTRA√éNEMENT DES MOD√àLES\n",
    "# ============================================================\n",
    "\n",
    "# √Ä tester plusieurs mod√®les...\n",
    "\n",
    "# ============================================================\n",
    "# 6. √âVALUATION & COMPARAISON\n",
    "# ============================================================\n",
    "\n",
    "# M√©triques de performance...\n",
    "\n",
    "# ============================================================\n",
    "# 7. OPTIMISATION DU MEILLEUR MOD√àLE\n",
    "# ============================================================\n",
    "\n",
    "# Hyperparameter tuning...\n",
    "\n",
    "# ============================================================\n",
    "# 8. SAUVEGARDE DU MOD√àLE FINAL\n",
    "# ============================================================\n",
    "\n",
    "# Pickle ou joblib..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "631bacb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 21 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Survived         891 non-null    int64  \n",
      " 1   Pclass           891 non-null    int64  \n",
      " 2   Name             891 non-null    object \n",
      " 3   Sex              891 non-null    object \n",
      " 4   Age              891 non-null    float64\n",
      " 5   SibSp            891 non-null    int64  \n",
      " 6   Parch            891 non-null    int64  \n",
      " 7   Ticket           891 non-null    object \n",
      " 8   Fare             891 non-null    float64\n",
      " 9   Cabin            891 non-null    object \n",
      " 10  Embarked         891 non-null    object \n",
      " 11  Title            891 non-null    object \n",
      " 12  Age_Was_Missing  891 non-null    int64  \n",
      " 13  Title_Is_Rare    891 non-null    int64  \n",
      " 14  Title_Simple     891 non-null    object \n",
      " 15  FamilySize       891 non-null    int64  \n",
      " 16  HasFamily        891 non-null    int64  \n",
      " 17  Large_Family     891 non-null    int64  \n",
      " 18  Deck             891 non-null    object \n",
      " 19  Fare_Category    891 non-null    object \n",
      " 20  Age_Category     891 non-null    object \n",
      "dtypes: float64(2), int64(9), object(10)\n",
      "memory usage: 146.3+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 21 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Survived         891 non-null    int64  \n",
      " 1   Pclass           891 non-null    int64  \n",
      " 2   Name             891 non-null    object \n",
      " 3   Sex              891 non-null    object \n",
      " 4   Age              891 non-null    float64\n",
      " 5   SibSp            891 non-null    int64  \n",
      " 6   Parch            891 non-null    int64  \n",
      " 7   Ticket           891 non-null    object \n",
      " 8   Fare             891 non-null    float64\n",
      " 9   Cabin            891 non-null    object \n",
      " 10  Embarked         891 non-null    object \n",
      " 11  Title            891 non-null    object \n",
      " 12  Age_Was_Missing  891 non-null    int64  \n",
      " 13  Title_Is_Rare    891 non-null    int64  \n",
      " 14  Title_Simple     891 non-null    object \n",
      " 15  FamilySize       891 non-null    int64  \n",
      " 16  HasFamily        891 non-null    int64  \n",
      " 17  Large_Family     891 non-null    int64  \n",
      " 18  Deck             891 non-null    object \n",
      " 19  Fare_Category    891 non-null    object \n",
      " 20  Age_Category     891 non-null    object \n",
      "dtypes: float64(2), int64(9), object(10)\n",
      "memory usage: 146.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "data.info()\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f164c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Statistiques rapides :\n",
      "   ‚Ä¢ Variables num√©riques : 8\n",
      "   ‚Ä¢ Variables cat√©gorielles : 2\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "features_to_keep = [\n",
    "    'Survived',           # TARGET\n",
    "    'Pclass',             # Classe sociale\n",
    "    'Sex',                # Sexe (impact majeur)\n",
    "    'Age',                # √Çge num√©rique\n",
    "    'Fare',               # Prix num√©rique\n",
    "    'Title_Simple',       # Titre simplifi√©\n",
    "    'FamilySize',         # Taille famille\n",
    "    'HasFamily',          # Flag famille\n",
    "    'Large_Family',       # Flag grande famille\n",
    "    'Age_Was_Missing'     # Flag age imput√©\n",
    "]\n",
    "\n",
    "data2 = data[features_to_keep].copy()\n",
    "\n",
    "print(f\"\\nüìä Statistiques rapides :\")\n",
    "print(f\"   ‚Ä¢ Variables num√©riques : {data2.select_dtypes(include=[np.number]).shape[1]}\")\n",
    "print(f\"   ‚Ä¢ Variables cat√©gorielles : {data2.select_dtypes(include=['object']).shape[1]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c5c18b",
   "metadata": {},
   "source": [
    "ENCODAGE\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c6f5894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ X (features) : (891, 9)\n",
      "‚úÖ y (target) : (891,)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# ENCODAGE DES VARIABLES CAT√âGORIELLES\n",
    "# ============================================================\n",
    "\n",
    "# S√©parer features et target\n",
    "X = data2.drop('Survived', axis=1).copy()\n",
    "y = data2['Survived'].copy()\n",
    "\n",
    "print(f\"\\n‚úÖ X (features) : {X.shape}\")\n",
    "print(f\"‚úÖ y (target) : {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ef41fb0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Sex', 'Title_Simple'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#===========================================================\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# ONE-HOT ENCODING DES VARIABLES CAT√âGORIELLES\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#===========================================================\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m X \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mget_dummies(X, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSex\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitle_Simple\u001b[39m\u001b[38;5;124m'\u001b[39m], drop_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m‚úÖ Dataset avec One-Hot : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   Nouvelles colonnes : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(X\u001b[38;5;241m.\u001b[39mcolumns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\encoding.py:169\u001b[0m, in \u001b[0;36mget_dummies\u001b[1;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput must be a list-like for parameter `columns`\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 169\u001b[0m     data_to_encode \u001b[38;5;241m=\u001b[39m data[columns]\n\u001b[0;32m    171\u001b[0m \u001b[38;5;66;03m# validate prefixes and separator to avoid silently dropping cols\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_len\u001b[39m(item, name: \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[0;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[1;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['Sex', 'Title_Simple'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "#===========================================================\n",
    "# ONE-HOT ENCODING DES VARIABLES CAT√âGORIELLES\n",
    "#===========================================================\n",
    "\n",
    "X = pd.get_dummies(X, columns=['Sex', 'Title_Simple'], drop_first=True)\n",
    "print(f\"\\n‚úÖ Dataset avec One-Hot : {X.shape}\")\n",
    "print(f\"   Nouvelles colonnes : {list(X.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ec892a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üîó CR√âATION DE FEATURES D'INTERACTION\n",
      "============================================================\n",
      "\n",
      "üìä Interactions √† cr√©er (bas√©es sur l'EDA) :\n",
      "   ‚úÖ 1. Sex √ó Pclass\n",
      "   ‚úÖ 2. Age √ó Sex\n",
      "   ‚úÖ 3. FamilySize √ó Pclass\n",
      "   ‚úÖ 4. Fare √ó Pclass\n",
      "   ‚úÖ 5. HasFamily √ó Pclass\n",
      "   ‚úÖ 6. Age √ó Pclass\n",
      "\n",
      "üìä R√©sultat :\n",
      "   X_base (sans interactions)  : 13 features\n",
      "   X_interact (avec interactions) : 19 features\n",
      "   ‚Üí 6 interactions ajout√©es\n",
      "\n",
      "üìã Nouvelles colonnes d'interaction :\n",
      "   1. Sex_male_x_Pclass\n",
      "   2. Age_x_Sex_male\n",
      "   3. FamilySize_x_Pclass\n",
      "   4. Fare_x_Pclass\n",
      "   5. HasFamily_x_Pclass\n",
      "   6. Age_x_Pclass\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CR√âATION DE FEATURES D'INTERACTION\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üîó CR√âATION DE FEATURES D'INTERACTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Version SANS interactions (pour Random Forest, XGBoost)\n",
    "X_base = X.copy()\n",
    "\n",
    "# Version AVEC interactions (pour Logistic Regression, SVM)\n",
    "X_interact = X.copy()\n",
    "\n",
    "# ============================================================\n",
    "# Interactions Cl√©s Identifi√©es dans l'EDA\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nüìä Interactions √† cr√©er (bas√©es sur l'EDA) :\")\n",
    "\n",
    "# 1. SEX √ó PCLASS (Impact majeur observ√©)\n",
    "# Les femmes en 1√®re classe ont ~97% survie vs ~50% en 3√®me\n",
    "X_interact['Sex_male_x_Pclass'] = X_interact['Sex_male'] * X_interact['Pclass']\n",
    "\n",
    "print(\"   ‚úÖ 1. Sex √ó Pclass\")\n",
    "\n",
    "# 2. AGE √ó SEX (Enfants vs Adultes, diff√©rent selon sexe)\n",
    "X_interact['Age_x_Sex_male'] = X_interact['Age'] * X_interact['Sex_male']\n",
    "\n",
    "print(\"   ‚úÖ 2. Age √ó Sex\")\n",
    "\n",
    "# 3. FAMILYSIZE √ó PCLASS (Grandes familles en 3√®me classe = danger)\n",
    "X_interact['FamilySize_x_Pclass'] = X_interact['FamilySize'] * X_interact['Pclass']\n",
    "\n",
    "print(\"   ‚úÖ 3. FamilySize √ó Pclass\")\n",
    "\n",
    "# 4. FARE √ó PCLASS (Nuances au sein d'une classe)\n",
    "X_interact['Fare_x_Pclass'] = X_interact['Fare'] * X_interact['Pclass']\n",
    "\n",
    "print(\"   ‚úÖ 4. Fare √ó Pclass\")\n",
    "\n",
    "# 5. HASFAMILY √ó PCLASS (Famille protectrice sauf en 3√®me classe)\n",
    "X_interact['HasFamily_x_Pclass'] = X_interact['HasFamily'] * X_interact['Pclass']\n",
    "\n",
    "print(\"   ‚úÖ 5. HasFamily √ó Pclass\")\n",
    "\n",
    "# 6. AGE √ó PCLASS (Enfants prioritaires, mais moins en 3√®me)\n",
    "X_interact['Age_x_Pclass'] = X_interact['Age'] * X_interact['Pclass']\n",
    "\n",
    "print(\"   ‚úÖ 6. Age √ó Pclass\")\n",
    "\n",
    "# ============================================================\n",
    "# V√âRIFICATION\n",
    "# ============================================================\n",
    "\n",
    "print(f\"\\nüìä R√©sultat :\")\n",
    "print(f\"   X_base (sans interactions)  : {X_base.shape[1]} features\")\n",
    "print(f\"   X_interact (avec interactions) : {X_interact.shape[1]} features\")\n",
    "print(f\"   ‚Üí {X_interact.shape[1] - X_base.shape[1]} interactions ajout√©es\")\n",
    "\n",
    "print(f\"\\nüìã Nouvelles colonnes d'interaction :\")\n",
    "interaction_cols = [col for col in X_interact.columns if '_x_' in col]\n",
    "for i, col in enumerate(interaction_cols, 1):\n",
    "    print(f\"   {i}. {col}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c769c16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Split BASE cr√©√©\n",
      "‚úÖ Split INTERACTIONS cr√©√©\n",
      "‚úÖ Standardisation appliqu√©e aux 2 versions\n",
      "\n",
      "============================================================\n",
      "üì¶ DATASETS PR√äTS POUR LE ML\n",
      "============================================================\n",
      "\n",
      "üéØ Pour mod√®les lin√©aires (Logistic, SVM) :\n",
      "   ‚Üí X_train_interact_scaled, X_test_interact_scaled\n",
      "\n",
      "üå≥ Pour mod√®les d'arbres (Random Forest, XGBoost) :\n",
      "   ‚Üí X_train_base, X_test_base\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# TRAIN/TEST SPLIT - VERSION BASE\n",
    "# ============================================================\n",
    "\n",
    "X_train_base, X_test_base, y_train, y_test = train_test_split(\n",
    "    X_base, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Split BASE cr√©√©\")\n",
    "\n",
    "# ============================================================\n",
    "# TRAIN/TEST SPLIT - VERSION AVEC INTERACTIONS\n",
    "# ============================================================\n",
    "\n",
    "X_train_interact, X_test_interact, _, _ = train_test_split(\n",
    "    X_interact, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,  # M√äME random_state !\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Split INTERACTIONS cr√©√©\")\n",
    "\n",
    "# ============================================================\n",
    "# STANDARDISATION - LES 2 VERSIONS\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Colonnes num√©riques √† standardiser\n",
    "numeric_cols = ['Pclass', 'Age', 'Fare', 'FamilySize']\n",
    "\n",
    "# BASE\n",
    "scaler_base = StandardScaler()\n",
    "X_train_base_scaled = X_train_base.copy()\n",
    "X_test_base_scaled = X_test_base.copy()\n",
    "X_train_base_scaled[numeric_cols] = scaler_base.fit_transform(X_train_base[numeric_cols])\n",
    "X_test_base_scaled[numeric_cols] = scaler_base.transform(X_test_base[numeric_cols])\n",
    "\n",
    "# INTERACTIONS (scaler sur TOUTES les colonnes num√©riques incluant interactions)\n",
    "numeric_cols_interact = numeric_cols + interaction_cols\n",
    "scaler_interact = StandardScaler()\n",
    "X_train_interact_scaled = X_train_interact.copy()\n",
    "X_test_interact_scaled = X_test_interact.copy()\n",
    "X_train_interact_scaled[numeric_cols_interact] = scaler_interact.fit_transform(X_train_interact[numeric_cols_interact])\n",
    "X_test_interact_scaled[numeric_cols_interact] = scaler_interact.transform(X_test_interact[numeric_cols_interact])\n",
    "\n",
    "print(\"‚úÖ Standardisation appliqu√©e aux 2 versions\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üì¶ DATASETS PR√äTS POUR LE ML\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nüéØ Pour mod√®les lin√©aires (Logistic, SVM) :\")\n",
    "print(f\"   ‚Üí X_train_interact_scaled, X_test_interact_scaled\")\n",
    "print(\"\\nüå≥ Pour mod√®les d'arbres (Random Forest, XGBoost) :\")\n",
    "print(f\"   ‚Üí X_train_base, X_test_base\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71891fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üîó CR√âATION DE FEATURES D'INTERACTION\n",
      "============================================================\n",
      "\n",
      "üìä Cr√©ation des interactions :\n",
      "   ‚úÖ 1. Sex_male √ó Pclass\n",
      "   ‚úÖ 2. Age √ó Sex_male\n",
      "   ‚úÖ 3. FamilySize √ó Pclass\n",
      "   ‚úÖ 4. Fare √ó Pclass\n",
      "   ‚úÖ 5. HasFamily √ó Pclass\n",
      "   ‚úÖ 6. Age √ó Pclass\n",
      "\n",
      "üìä R√©sultat :\n",
      "   X_base : 13 features\n",
      "   X_interact : 19 features (+6 interactions)\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CR√âATION DE FEATURES D'INTERACTION\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üîó CR√âATION DE FEATURES D'INTERACTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Version SANS interactions (pour Random Forest, XGBoost)\n",
    "X_base = X.copy()\n",
    "\n",
    "# Version AVEC interactions (pour Logistic Regression, SVM)\n",
    "X_interact = X.copy()\n",
    "\n",
    "# ============================================================\n",
    "# Interactions Cl√©s (bas√©es sur l'EDA)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nüìä Cr√©ation des interactions :\")\n",
    "\n",
    "# 1. SEX √ó PCLASS - Impact majeur observ√©\n",
    "if 'Sex_male' in X_interact.columns:\n",
    "    X_interact['Sex_male_x_Pclass'] = X_interact['Sex_male'] * X_interact['Pclass']\n",
    "    print(\"   ‚úÖ 1. Sex_male √ó Pclass\")\n",
    "\n",
    "# 2. AGE √ó SEX - Enfants vs Adultes diff√©rent selon sexe\n",
    "if 'Sex_male' in X_interact.columns:\n",
    "    X_interact['Age_x_Sex_male'] = X_interact['Age'] * X_interact['Sex_male']\n",
    "    print(\"   ‚úÖ 2. Age √ó Sex_male\")\n",
    "\n",
    "# 3. FAMILYSIZE √ó PCLASS - Grandes familles en 3√®me = danger\n",
    "X_interact['FamilySize_x_Pclass'] = X_interact['FamilySize'] * X_interact['Pclass']\n",
    "print(\"   ‚úÖ 3. FamilySize √ó Pclass\")\n",
    "\n",
    "# 4. FARE √ó PCLASS - Nuances au sein d'une classe\n",
    "X_interact['Fare_x_Pclass'] = X_interact['Fare'] * X_interact['Pclass']\n",
    "print(\"   ‚úÖ 4. Fare √ó Pclass\")\n",
    "\n",
    "# 5. HASFAMILY √ó PCLASS - Famille protectrice sauf en 3√®me\n",
    "X_interact['HasFamily_x_Pclass'] = X_interact['HasFamily'] * X_interact['Pclass']\n",
    "print(\"   ‚úÖ 5. HasFamily √ó Pclass\")\n",
    "\n",
    "# 6. AGE √ó PCLASS - Enfants prioritaires, moins en 3√®me\n",
    "X_interact['Age_x_Pclass'] = X_interact['Age'] * X_interact['Pclass']\n",
    "print(\"   ‚úÖ 6. Age √ó Pclass\")\n",
    "\n",
    "# Colonnes d'interaction cr√©√©es\n",
    "interaction_cols = [col for col in X_interact.columns if '_x_' in col]\n",
    "\n",
    "print(f\"\\nüìä R√©sultat :\")\n",
    "print(f\"   X_base : {X_base.shape[1]} features\")\n",
    "print(f\"   X_interact : {X_interact.shape[1]} features (+{len(interaction_cols)} interactions)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7445a185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "‚úÇÔ∏è S√âPARATION TRAIN/TEST\n",
      "============================================================\n",
      "\n",
      "üì¶ VERSION BASE :\n",
      "   Train : (712, 13)\n",
      "   Test  : (179, 13)\n",
      "\n",
      "üì¶ VERSION INTERACTIONS :\n",
      "   Train : (712, 19)\n",
      "   Test  : (179, 19)\n",
      "\n",
      "‚öñÔ∏è Distribution survie :\n",
      "   Train : 38.3%\n",
      "   Test  : 38.5%\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# TRAIN/TEST SPLIT\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"‚úÇÔ∏è S√âPARATION TRAIN/TEST\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# VERSION BASE (sans interactions)\n",
    "X_train_base, X_test_base, y_train, y_test = train_test_split(\n",
    "    X_base, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nüì¶ VERSION BASE :\")\n",
    "print(f\"   Train : {X_train_base.shape}\")\n",
    "print(f\"   Test  : {X_test_base.shape}\")\n",
    "\n",
    "# VERSION AVEC INTERACTIONS (M√äME random_state !)\n",
    "X_train_interact, X_test_interact, _, _ = train_test_split(\n",
    "    X_interact, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,  # Important : m√™me split !\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nüì¶ VERSION INTERACTIONS :\")\n",
    "print(f\"   Train : {X_train_interact.shape}\")\n",
    "print(f\"   Test  : {X_test_interact.shape}\")\n",
    "\n",
    "print(f\"\\n‚öñÔ∏è Distribution survie :\")\n",
    "print(f\"   Train : {y_train.mean():.1%}\")\n",
    "print(f\"   Test  : {y_test.mean():.1%}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b9151c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üìè STANDARDISATION DES FEATURES\n",
      "============================================================\n",
      "‚úÖ Base standardis√©e\n",
      "‚úÖ Interactions standardis√©es\n",
      "\n",
      "============================================================\n",
      "üì¶ R√âCAPITULATIF DES DATASETS\n",
      "============================================================\n",
      "\n",
      "üå≥ Pour Random Forest, XGBoost :\n",
      "   ‚Üí X_train_base (13 features)\n",
      "   ‚Üí X_test_base (13 features)\n",
      "\n",
      "üìà Pour Logistic Regression, SVM :\n",
      "   ‚Üí X_train_interact_scaled (19 features)\n",
      "   ‚Üí X_test_interact_scaled (19 features)\n",
      "\n",
      "üéØ Target :\n",
      "   ‚Üí y_train (712 samples)\n",
      "   ‚Üí y_test (179 samples)\n",
      "============================================================\n",
      "‚úÖ PR√äT POUR L'ENTRA√éNEMENT !\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STANDARDISATION\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üìè STANDARDISATION DES FEATURES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Colonnes num√©riques de base\n",
    "numeric_cols = ['Pclass', 'Age', 'Fare', 'FamilySize']\n",
    "\n",
    "# VERSION BASE\n",
    "scaler_base = StandardScaler()\n",
    "X_train_base_scaled = X_train_base.copy()\n",
    "X_test_base_scaled = X_test_base.copy()\n",
    "\n",
    "X_train_base_scaled[numeric_cols] = scaler_base.fit_transform(X_train_base[numeric_cols])\n",
    "X_test_base_scaled[numeric_cols] = scaler_base.transform(X_test_base[numeric_cols])\n",
    "\n",
    "print(f\"‚úÖ Base standardis√©e\")\n",
    "\n",
    "# VERSION INTERACTIONS (standardiser aussi les interactions)\n",
    "numeric_cols_interact = numeric_cols + interaction_cols\n",
    "\n",
    "scaler_interact = StandardScaler()\n",
    "X_train_interact_scaled = X_train_interact.copy()\n",
    "X_test_interact_scaled = X_test_interact.copy()\n",
    "\n",
    "X_train_interact_scaled[numeric_cols_interact] = scaler_interact.fit_transform(\n",
    "    X_train_interact[numeric_cols_interact]\n",
    ")\n",
    "X_test_interact_scaled[numeric_cols_interact] = scaler_interact.transform(\n",
    "    X_test_interact[numeric_cols_interact]\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Interactions standardis√©es\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üì¶ R√âCAPITULATIF DES DATASETS\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nüå≥ Pour Random Forest, XGBoost :\")\n",
    "print(f\"   ‚Üí X_train_base ({X_train_base.shape[1]} features)\")\n",
    "print(f\"   ‚Üí X_test_base ({X_test_base.shape[1]} features)\")\n",
    "\n",
    "print(\"\\nüìà Pour Logistic Regression, SVM :\")\n",
    "print(f\"   ‚Üí X_train_interact_scaled ({X_train_interact_scaled.shape[1]} features)\")\n",
    "print(f\"   ‚Üí X_test_interact_scaled ({X_test_interact_scaled.shape[1]} features)\")\n",
    "\n",
    "print(\"\\nüéØ Target :\")\n",
    "print(f\"   ‚Üí y_train ({len(y_train)} samples)\")\n",
    "print(f\"   ‚Üí y_test ({len(y_test)} samples)\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"‚úÖ PR√äT POUR L'ENTRA√éNEMENT !\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad45b34c",
   "metadata": {},
   "source": [
    "‚úÖ X_train_base, X_test_base ‚Üí Pour Random Forest, XGBoost (pas d'interactions n√©cessaires)\n",
    "‚úÖ X_train_base_scaled, X_test_base_scaled ‚Üí Pour mod√®les lin√©aires version simple\n",
    "‚úÖ X_train_interact_scaled, X_test_interact_scaled ‚Üí Pour Logistic/SVM avec interactions\n",
    "‚úÖ y_train, y_test ‚Üí Target identique pour tous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0570dae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üìä BASELINE - PR√âDIRE TOUJOURS LA CLASSE MAJORITAIRE\n",
      "======================================================================\n",
      "\n",
      "Classe majoritaire : 0 (D√©c√©d√©)\n",
      "\n",
      "üéØ BASELINE ACCURACY : 0.6145 (61.45%)\n",
      "\n",
      "üí° Objectif : Nos mod√®les doivent faire MIEUX que 61.45% !\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# BASELINE : PR√âDIRE TOUJOURS LA CLASSE MAJORITAIRE\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üìä BASELINE - PR√âDIRE TOUJOURS LA CLASSE MAJORITAIRE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Classe majoritaire dans le train\n",
    "baseline_prediction = y_train.mode()[0]\n",
    "print(f\"\\nClasse majoritaire : {baseline_prediction} ({'D√©c√©d√©' if baseline_prediction == 0 else 'Surv√©cu'})\")\n",
    "\n",
    "# Pr√©dire toujours cette classe\n",
    "y_pred_baseline = [baseline_prediction] * len(y_test)\n",
    "\n",
    "# Accuracy baseline\n",
    "baseline_accuracy = accuracy_score(y_test, y_pred_baseline)\n",
    "\n",
    "print(f\"\\nüéØ BASELINE ACCURACY : {baseline_accuracy:.4f} ({baseline_accuracy*100:.2f}%)\")\n",
    "print(f\"\\nüí° Objectif : Nos mod√®les doivent faire MIEUX que {baseline_accuracy*100:.2f}% !\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d0651a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üìà MOD√àLE 1 : LOGISTIC REGRESSION (avec interactions)\n",
      "======================================================================\n",
      "\n",
      "üìä R√âSULTATS :\n",
      "   Accuracy Train : 0.8413 (84.13%)\n",
      "   Accuracy Test  : 0.8436 (84.36%)\n",
      "   ROC-AUC Score  : 0.8755\n",
      "   Overfitting    : -0.23%\n",
      "\n",
      "üìã MATRICE DE CONFUSION :\n",
      "[[99 11]\n",
      " [17 52]]\n",
      "\n",
      "   TN=99, FP=11\n",
      "   FN=17, TP=52\n",
      "\n",
      "üìù CLASSIFICATION REPORT :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      D√©c√©d√©       0.85      0.90      0.88       110\n",
      "     Surv√©cu       0.83      0.75      0.79        69\n",
      "\n",
      "    accuracy                           0.84       179\n",
      "   macro avg       0.84      0.83      0.83       179\n",
      "weighted avg       0.84      0.84      0.84       179\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# MOD√àLE 1 : LOGISTIC REGRESSION (avec interactions)\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üìà MOD√àLE 1 : LOGISTIC REGRESSION (avec interactions)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Entra√Æner\n",
    "lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr_model.fit(X_train_interact_scaled, y_train)\n",
    "\n",
    "# Pr√©dictions\n",
    "y_pred_lr_train = lr_model.predict(X_train_interact_scaled)\n",
    "y_pred_lr_test = lr_model.predict(X_test_interact_scaled)\n",
    "\n",
    "# Probabilit√©s (pour ROC-AUC)\n",
    "y_pred_lr_proba = lr_model.predict_proba(X_test_interact_scaled)[:, 1]\n",
    "\n",
    "# M√©triques\n",
    "lr_train_acc = accuracy_score(y_train, y_pred_lr_train)\n",
    "lr_test_acc = accuracy_score(y_test, y_pred_lr_test)\n",
    "lr_roc_auc = roc_auc_score(y_test, y_pred_lr_proba)\n",
    "\n",
    "print(f\"\\nüìä R√âSULTATS :\")\n",
    "print(f\"   Accuracy Train : {lr_train_acc:.4f} ({lr_train_acc*100:.2f}%)\")\n",
    "print(f\"   Accuracy Test  : {lr_test_acc:.4f} ({lr_test_acc*100:.2f}%)\")\n",
    "print(f\"   ROC-AUC Score  : {lr_roc_auc:.4f}\")\n",
    "print(f\"   Overfitting    : {(lr_train_acc - lr_test_acc)*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nüìã MATRICE DE CONFUSION :\")\n",
    "cm_lr = confusion_matrix(y_test, y_pred_lr_test)\n",
    "print(cm_lr)\n",
    "print(f\"\\n   TN={cm_lr[0,0]}, FP={cm_lr[0,1]}\")\n",
    "print(f\"   FN={cm_lr[1,0]}, TP={cm_lr[1,1]}\")\n",
    "\n",
    "print(f\"\\nüìù CLASSIFICATION REPORT :\")\n",
    "print(classification_report(y_test, y_pred_lr_test, target_names=['D√©c√©d√©', 'Surv√©cu']))\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41fa00b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üå≥ MOD√àLE 2 : RANDOM FOREST (sans interactions)\n",
      "======================================================================\n",
      "\n",
      "üìä R√âSULTATS :\n",
      "   Accuracy Train : 0.9199 (91.99%)\n",
      "   Accuracy Test  : 0.8045 (80.45%)\n",
      "   ROC-AUC Score  : 0.8642\n",
      "   Overfitting    : 11.55%\n",
      "\n",
      "üìã MATRICE DE CONFUSION :\n",
      "[[95 15]\n",
      " [20 49]]\n",
      "\n",
      "   TN=95, FP=15\n",
      "   FN=20, TP=49\n",
      "\n",
      "üìù CLASSIFICATION REPORT :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      D√©c√©d√©       0.83      0.86      0.84       110\n",
      "     Surv√©cu       0.77      0.71      0.74        69\n",
      "\n",
      "    accuracy                           0.80       179\n",
      "   macro avg       0.80      0.79      0.79       179\n",
      "weighted avg       0.80      0.80      0.80       179\n",
      "\n",
      "\n",
      "‚≠ê TOP 10 FEATURES IMPORTANTES :\n",
      "   Fare                      : 0.2295\n",
      "   Title_Simple_Mr           : 0.1661\n",
      "   Sex_male                  : 0.1642\n",
      "   Age                       : 0.1562\n",
      "   Pclass                    : 0.0905\n",
      "   FamilySize                : 0.0606\n",
      "   Title_Simple_Miss         : 0.0402\n",
      "   Title_Simple_Mrs          : 0.0347\n",
      "   Large_Family              : 0.0311\n",
      "   HasFamily                 : 0.0135\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# MOD√àLE 2 : RANDOM FOREST (sans interactions)\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üå≥ MOD√àLE 2 : RANDOM FOREST (sans interactions)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Entra√Æner\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5\n",
    ")\n",
    "rf_model.fit(X_train_base, y_train)\n",
    "\n",
    "# Pr√©dictions\n",
    "y_pred_rf_train = rf_model.predict(X_train_base)\n",
    "y_pred_rf_test = rf_model.predict(X_test_base)\n",
    "y_pred_rf_proba = rf_model.predict_proba(X_test_base)[:, 1]\n",
    "\n",
    "# M√©triques\n",
    "rf_train_acc = accuracy_score(y_train, y_pred_rf_train)\n",
    "rf_test_acc = accuracy_score(y_test, y_pred_rf_test)\n",
    "rf_roc_auc = roc_auc_score(y_test, y_pred_rf_proba)\n",
    "\n",
    "print(f\"\\nüìä R√âSULTATS :\")\n",
    "print(f\"   Accuracy Train : {rf_train_acc:.4f} ({rf_train_acc*100:.2f}%)\")\n",
    "print(f\"   Accuracy Test  : {rf_test_acc:.4f} ({rf_test_acc*100:.2f}%)\")\n",
    "print(f\"   ROC-AUC Score  : {rf_roc_auc:.4f}\")\n",
    "print(f\"   Overfitting    : {(rf_train_acc - rf_test_acc)*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nüìã MATRICE DE CONFUSION :\")\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf_test)\n",
    "print(cm_rf)\n",
    "print(f\"\\n   TN={cm_rf[0,0]}, FP={cm_rf[0,1]}\")\n",
    "print(f\"   FN={cm_rf[1,0]}, TP={cm_rf[1,1]}\")\n",
    "\n",
    "print(f\"\\nüìù CLASSIFICATION REPORT :\")\n",
    "print(classification_report(y_test, y_pred_rf_test, target_names=['D√©c√©d√©', 'Surv√©cu']))\n",
    "\n",
    "# Feature Importance\n",
    "print(f\"\\n‚≠ê TOP 10 FEATURES IMPORTANTES :\")\n",
    "feature_imp = pd.DataFrame({\n",
    "    'Feature': X_train_base.columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "for idx, row in feature_imp.head(10).iterrows():\n",
    "    print(f\"   {row['Feature']:25s} : {row['Importance']:.4f}\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "194cd5f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# MOD√àLE 3 : XGBOOST (sans interactions)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m70\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müöÄ MOD√àLE 3 : XGBOOST (sans interactions)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# MOD√àLE 3 : XGBOOST (sans interactions)\n",
    "# ============================================================\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üöÄ MOD√àLE 3 : XGBOOST (sans interactions)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Entra√Æner\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    random_state=42,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "xgb_model.fit(X_train_base, y_train)\n",
    "\n",
    "# Pr√©dictions\n",
    "y_pred_xgb_train = xgb_model.predict(X_train_base)\n",
    "y_pred_xgb_test = xgb_model.predict(X_test_base)\n",
    "y_pred_xgb_proba = xgb_model.predict_proba(X_test_base)[:, 1]\n",
    "\n",
    "# M√©triques\n",
    "xgb_train_acc = accuracy_score(y_train, y_pred_xgb_train)\n",
    "xgb_test_acc = accuracy_score(y_test, y_pred_xgb_test)\n",
    "xgb_roc_auc = roc_auc_score(y_test, y_pred_xgb_proba)\n",
    "\n",
    "print(f\"\\nüìä R√âSULTATS :\")\n",
    "print(f\"   Accuracy Train : {xgb_train_acc:.4f} ({xgb_train_acc*100:.2f}%)\")\n",
    "print(f\"   Accuracy Test  : {xgb_test_acc:.4f} ({xgb_test_acc*100:.2f}%)\")\n",
    "print(f\"   ROC-AUC Score  : {xgb_roc_auc:.4f}\")\n",
    "print(f\"   Overfitting    : {(xgb_train_acc - xgb_test_acc)*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nüìã MATRICE DE CONFUSION :\")\n",
    "cm_xgb = confusion_matrix(y_test, y_pred_xgb_test)\n",
    "print(cm_xgb)\n",
    "print(f\"\\n   TN={cm_xgb[0,0]}, FP={cm_xgb[0,1]}\")\n",
    "print(f\"   FN={cm_xgb[1,0]}, TP={cm_xgb[1,1]}\")\n",
    "\n",
    "print(f\"\\nüìù CLASSIFICATION REPORT :\")\n",
    "print(classification_report(y_test, y_pred_xgb_test, target_names=['D√©c√©d√©', 'Surv√©cu']))\n",
    "\n",
    "# Feature Importance\n",
    "print(f\"\\n‚≠ê TOP 10 FEATURES IMPORTANTES :\")\n",
    "feature_imp_xgb = pd.DataFrame({\n",
    "    'Feature': X_train_base.columns,\n",
    "    'Importance': xgb_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "for idx, row in feature_imp_xgb.head(10).iterrows():\n",
    "    print(f\"   {row['Feature']:25s} : {row['Importance']:.4f}\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e677be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# COMPARAISON DES MOD√àLES\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üìä COMPARAISON DES PERFORMANCES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'Mod√®le': ['Baseline', 'Logistic Regression', 'Random Forest', 'XGBoost'],\n",
    "    'Accuracy Test': [\n",
    "        baseline_accuracy,\n",
    "        lr_test_acc,\n",
    "        rf_test_acc,\n",
    "        xgb_test_acc\n",
    "    ],\n",
    "    'ROC-AUC': [\n",
    "        0.5,\n",
    "        lr_roc_auc,\n",
    "        rf_roc_auc,\n",
    "        xgb_roc_auc\n",
    "    ],\n",
    "    'Overfitting': [\n",
    "        0,\n",
    "        (lr_train_acc - lr_test_acc),\n",
    "        (rf_train_acc - rf_test_acc),\n",
    "        (xgb_train_acc - xgb_test_acc)\n",
    "    ]\n",
    "})\n",
    "\n",
    "results = results.sort_values('Accuracy Test', ascending=False)\n",
    "display(results)\n",
    "\n",
    "print(f\"\\nüèÜ MEILLEUR MOD√àLE : {results.iloc[0]['Mod√®le']}\")\n",
    "print(f\"   Accuracy : {results.iloc[0]['Accuracy Test']:.4f}\")\n",
    "print(f\"   ROC-AUC  : {results.iloc[0]['ROC-AUC']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
